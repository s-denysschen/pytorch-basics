{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to PyTorch\n",
    "### What is a Tensor? \n",
    "A tensor, in the context of PyTorch, is a multi-dimensional array used to represent data. It's similar to arrays in Python or ndarrays in NumPy, but with additional features that make it suitable for deep learning applications.\n",
    "\n",
    "### Installation of PyTorch\n",
    "Before we start coding, you need to install PyTorch. Assuming that you have Python installed, you can install PyTorch by running the following command in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ab012dh\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ab012dh\\appdata\\roaming\\python\\python39\\site-packages (0.15.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ab012dh\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ab012dh\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ab012dh\\anaconda3\\lib\\site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\ab012dh\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ab012dh\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ab012dh\\anaconda3\\lib\\site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ab012dh\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ab012dh\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\ab012dh\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ab012dh\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ab012dh\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ab012dh\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ab012dh\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ab012dh\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch torchvision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command installs not only PyTorch (torch), but also torchvision (torchvision), which provides datasets and model architectures for computer vision."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started with Tensors\n",
    "To start with PyTorch, we need to import it,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AB012DH\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\AB012DH\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\AB012DH\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a tensor with a specific data type using torch.tensor(). Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1, 2, 3])\n",
    "print(t1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we've created a 1-dimensional tensor. You can also create a 2-dimensional tensor like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.tensor([[1, 2], [3, 4]])\n",
    "print(t2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the shape of a tensor (i.e., its dimensions) using the .shape attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(t2.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells you that t2 is a 2x2 tensor (a matrix with 2 rows and 2 columns)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mathematical Operations\n",
    "Now let's dive into some mathematical operations that we can perform on tensors.\n",
    "\n",
    "Addition:\n",
    "\n",
    "You can add two tensors of the same shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1, 2, 3])\n",
    "t2 = torch.tensor([4, 5, 6])\n",
    "t3 = t1 + t2\n",
    "\n",
    "print(t3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplication:\n",
    "\n",
    "You can also multiply two tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4, 10, 18])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1, 2, 3])\n",
    "t2 = torch.tensor([4, 5, 6])\n",
    "t3 = t1 * t2\n",
    "\n",
    "print(t3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is element-wise multiplication, not matrix multiplication.\n",
    "\n",
    "Matrix Multiplication:\n",
    "\n",
    "For matrix multiplication, you can use torch.matmul():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  6],\n",
      "        [18, 19]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2], [4, 3]])\n",
    "t2 = torch.tensor([[3, 4], [2, 1]])\n",
    "t3 = torch.matmul(t1, t2)\n",
    "\n",
    "print(t3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing, Slicing, Joining, and Mutation\n",
    "In this lesson, we will further explore how to manipulate tensors in PyTorch. The operations we will focus on are indexing, slicing, joining, and mutating tensors.\n",
    "\n",
    "#### Indexing and Slicing\n",
    "Like in Python and many other languages, indexing in PyTorch starts at 0. Let's create a 1-D tensor and access its elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "# accessing the first element\n",
    "print(t1[0])\n",
    "\n",
    "# accessing the last element\n",
    "print(t1[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing works similarly to Python's list slicing. You can select a range of elements in a tensor using the syntax [start:end]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(t1[1:3])  # prints elements at index 1 and 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing and slicing for multi-dimensional tensors work similarly, just with additional dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n",
      "tensor([[4, 5],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# accessing a single element\n",
    "print(t2[1, 2])  # prints element at row 1, column 2\n",
    "\n",
    "# slicing\n",
    "print(t2[1:, :2])  # prints all rows starting from 1, and columns up to 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining Tensors\n",
    "You can join multiple tensors into one. The most common way to do this is by using torch.cat():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1, 2, 3])\n",
    "t2 = torch.tensor([4, 5, 6])\n",
    "\n",
    "# concatenating along the 0th dimension\n",
    "t3 = torch.cat((t1, t2), dim=0)\n",
    "\n",
    "print(t3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also concatenate 2-D tensors along either dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2], [3, 4]])\n",
    "t2 = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "t3 = torch.cat((t1, t2), dim=0)  # concatenating along rows\n",
    "print(t3)\n",
    "\n",
    "t4 = torch.cat((t1, t2), dim=1)  # concatenating along columns\n",
    "print(t4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutation\n",
    "Finally, let's look at how to modify a tensor. You can change an element of a tensor by accessing it and assigning a new value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 7, 3])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1, 2, 3])\n",
    "\n",
    "t1[1] = 7  # changing the second element\n",
    "\n",
    "print(t1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also modify a slice of a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 7, 8, 9, 5])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "t1[1:4] = torch.tensor([7, 8, 9])  # changing elements at index 1, 2, and 3\n",
    "\n",
    "print(t1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that PyTorch tensors are mutable, meaning you can change their content without creating a new tensor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA support, Moving computations to GPU\n",
    "Deep learning models can be computationally intensive, and running them on a CPU can be slow. That's where Graphics Processing Units (GPUs) come in. GPUs are designed for performing large numbers of computations simultaneously, making them ideal for deep learning.\n",
    "CUDA (Compute Unified Device Architecture) is a parallel computing platform and application programming interface (API) model created by Nvidia for general computing on its own GPUs. PyTorch has built-in support for CUDA, which allows it to seamlessly perform computations on a GPU, if one is available.\n",
    "\n",
    "#### Checking for CUDA Availability\n",
    "Before we can move computations to a GPU, we first need to check whether CUDA is available. We can do this using torch.cuda.is_available():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will output True if CUDA is available and False otherwise.\n",
    "\n",
    "#### Moving Tensors to GPU\n",
    "You can create a tensor on a GPU directly, or move a tensor from CPU to GPU.\n",
    "\n",
    "To create a tensor on a GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([1, 2, 3], device='cuda')\n",
    "print(t1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, 'cuda:0' refers to the first GPU. If you have multiple GPUs and you want to create a tensor on the second GPU, you would use 'cuda:1', and so on.\n",
    "\n",
    "To move a tensor from CPU to GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = torch.tensor([4, 5, 6])\n",
    "t2 = t2.to('cuda')\n",
    "\n",
    "print(t2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Computations on GPU\n",
    "Once a tensor is on a GPU, any operations performed on it are carried out on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([1, 2, 3], device='cuda')\n",
    "t2 = torch.tensor([4, 5, 6], device='cuda')\n",
    "\n",
    "t3 = t1 + t2  # this computation is performed on the GPU\n",
    "\n",
    "print(t3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to ensure that all tensors involved in an operation are on the same device. If they're not, you'll need to move them first. Note that while using a GPU can greatly speed up computations, it also comes with its own challenges, such as managing GPU memory. However, these are stories for a more advanced tutorial."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Differentiation with Autograd\n",
    "When training neural networks, we often need to compute the gradients of loss functions with respect to the model's parameters, which are then used to update the parameters. This can be done using a technique called backpropagation.\n",
    "Luckily, PyTorch provides a package called autograd for automatic differentiation, which simplifies the computation of backward passes. This is an essential tool for neural networks, and PyTorch makes it quite easy to use.\n",
    "\n",
    "#### Tensors and Gradients\n",
    "In PyTorch, you can tell an autograd-compatible tensor to remember its operations for backpropagation using .requires_grad_(True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "print(t1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tensor t1 now has the ability to keep track of every operation involving it. Now, let's perform some operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "t2 = t1 * 2\n",
    "t3 = t2.mean()\n",
    "print(t3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, t3 is created as a result of operations involving t1, so it has a grad_fn.\n",
    "#### Backward Propagation\n",
    "To perform backpropagation, we call .backward() on the tensor. This computes the gradient of t3 with respect to t1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3.backward()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calling .backward(), the gradients are stored in the .grad attribute of the original tensor (t1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6667, 0.6667, 0.6667])\n"
     ]
    }
   ],
   "source": [
    "print(t1.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient stored in t1.grad is the partial derivative of t3 with respect to t1. It's important to note that if t1's shape doesn't match with t3, PyTorch won't be able to directly compute the gradients. That's why when we are dealing with scalar loss in a neural network, we don't have to provide any arguments to backward(). Also, PyTorch accumulates the gradient in the .grad attribute, which means that it doesn't overwrite the previous values but instead adds the newly computed gradient. To clear the gradients for a new operation, you need to call .grad.zero_().\n",
    "\n",
    "### PyTorch Libraries: Torchtext, torchvision, torchaudio\n",
    "PyTorch is not just a deep learning library; it also has several companion libraries that provide additional functionality, such as handling specific types of data and performing various common operations. Today, we'll discuss three of these libraries: Torchtext, torchvision, and torchaudio.\n",
    "\n",
    "#### Torchtext\n",
    "\n",
    "Torchtext is a library for handling text data. It provides tools for creating datasets, handling tokenization, and managing vocabularies. It also includes several common datasets and pre-trained embeddings (like Word2Vec or GloVe). Here is a simple example of using Torchtext:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, TabularDataset\n",
    "\n",
    "# Define fields\n",
    "TEXT = Field(sequential=True, tokenize='spacy', lower=True)\n",
    "LABEL = Field(sequential=False, use_vocab=False)\n",
    "\n",
    "# Define dataset\n",
    "datafields = [(\"text\", TEXT), (\"label\", LABEL)]\n",
    "dataset = TabularDataset(path=\"mydata.csv\", format='csv', fields=datafields)\n",
    "\n",
    "# Build vocab\n",
    "TEXT.build_vocab(dataset, vectors=\"glove.6B.100d\")\n",
    "\n",
    "# Now you can access the vocab using TEXT.vocab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Torchvision\n",
    "\n",
    "Torchvision is a library for handling image data. It includes tools for transforming images, common image datasets (like CIFAR10, MNIST), and pre-trained models (like ResNet, VGG). Here is a simple example of using torchvision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load a dataset\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# torchvision also provides pre-trained models\n",
    "from torchvision import models\n",
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torchaudio\n",
    "\n",
    "Torchaudio is a library for handling audio data. It provides tools for loading and saving audio data, transformations (like spectrograms, mel-scaling), and some common audio datasets. Here is a simple example of using torchaudio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchaudio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\AB012DH\\Desktop\\Learning\\Deep learning\\PyTorch\\intro.ipynb Cell 56\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/AB012DH/Desktop/Learning/Deep%20learning/PyTorch/intro.ipynb#Y113sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchaudio\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/AB012DH/Desktop/Learning/Deep%20learning/PyTorch/intro.ipynb#Y113sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Load an audio file\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/AB012DH/Desktop/Learning/Deep%20learning/PyTorch/intro.ipynb#Y113sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m waveform, sample_rate \u001b[39m=\u001b[39m torchaudio\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39maudio.wav\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchaudio'"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "\n",
    "# Load an audio file\n",
    "waveform, sample_rate = torchaudio.load('audio.wav')\n",
    "\n",
    "# Apply a transform\n",
    "transform = torchaudio.transforms.MFCC(sample_rate=sample_rate)\n",
    "mfcc = transform(waveform)\n",
    "\n",
    "# torchaudio also includes some common datasets\n",
    "yesno_data = torchaudio.datasets.YESNO('.', download=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
